[
["index.html", "Phylogenetic Biology Preface 0.1 Source code 0.2 Other resources 0.3 Software versions 0.4 License", " Phylogenetic Biology Casey W. Dunn 2020-09-22 Preface I developed this book as a collection of the concepts, methods, and applications that I most wanted to share with students in my Phylogenetic Biology courses. It is really my lecture notes dessed up in the form of the rough draft of a book. 0.1 Source code The source code for this manuscript is available on github. The book was rendered from the source with bookdown (Xie 2016). Please submit any errors you find, typos, or suggestions that you have for improving the manuscript to the issue tracker. 0.2 Other resources The following sites have a wide variety of material that is relevant to the theory and and practice of phylogenetic biology. An extensive list of tools, tutorials, and examples of phylogenetic tools in the programming language R maintained by Briam O’Meara: CRAN Task View: Phylogenetics The Workshop on Molecular Evolution at Woods Hole. This is an intensive summer course on phylogenetics, with an emphasis on building phylogenetic trees. Check out the faculty pages for lecture pdfs: Workshop on Molecular Evolution The Applied Phylogenetics Workshop in Bodega Bay. This is another summer course on phylogenetics, but with a bit more emphasis on using phylogenies to test evolutionary questions: Applied Phylogenetics Workshop The following books are great resources for learning more about phylogenetic biology: Baum, D. and Smith, S. (2012). Tree Thinking. An Introduction to Phylogenetic Biology. Roberts Publishers. Paradis, E. (2011) Analysis of Phylogenetics and Evolution with R. Springer Felsenstein, J. (2004) Inferring phylogenies. Sinauer Associates. Swofford, D. L., Olsen, G. J., Waddell, P. J., &amp; Hillis, D. M. (1996). Phylogenetic inference. In: Molecular Systematics, Second Edition. eds: D. M. Hillis, C Moritz, &amp; B. K. Mable. Sinauer Associates The following books provide general computational background for the topics covered here: Wickham, H., Grolemund, G (2017) R for Data Science. https://r4ds.had.co.nz Haddock, S. H. D. and Dunn, C. W. (2010). Practical Computing for Biologists. http://practicalcomputing.org 0.3 Software versions This book was rendered from the source code on Tue Sep 22 08:42:42 2020 with the following R package versions. R version 4.0.2 (2020-06-22) Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.6 Matrix products: default BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] kableExtra_1.2.1 phangorn_2.5.5 Matrix_1.2-18 forcats_0.5.0 [5] dplyr_1.0.2 purrr_0.3.4 readr_1.3.1 tidyr_1.1.2 [9] tibble_3.0.3 ggplot2_3.3.2 tidyverse_1.3.0 stringr_1.4.0 [13] phytools_0.7-47 maps_3.3.0 magrittr_1.5 gridExtra_2.3 [17] geiger_2.0.7 ape_5.4-1 ggtree_2.2.4 treeio_1.12.0 loaded via a namespace (and not attached): [1] subplex_1.6 nlme_3.1-149 fs_1.5.0 [4] lubridate_1.7.9 webshot_0.5.2 httr_1.4.2 [7] numDeriv_2016.8-1.1 tools_4.0.2 backports_1.1.10 [10] R6_2.4.1 DBI_1.1.0 lazyeval_0.2.2 [13] colorspace_1.4-1 withr_2.2.0 tidyselect_1.1.0 [16] mnormt_2.0.2 compiler_4.0.2 cli_2.0.2 [19] rvest_0.3.6 animation_2.6 expm_0.999-5 [22] xml2_1.3.2 bookdown_0.20 scales_1.1.1 [25] mvtnorm_1.1-1 quadprog_1.5-8 digest_0.6.25 [28] rmarkdown_2.3 pkgconfig_2.0.3 htmltools_0.5.0 [31] plotrix_3.7-8 dbplyr_1.4.4 rlang_0.4.7 [34] readxl_1.3.1 rstudioapi_0.11 generics_0.0.2 [37] combinat_0.0-8 jsonlite_1.7.1 gtools_3.8.2 [40] patchwork_1.0.1 fansi_0.4.1 Rcpp_1.0.5 [43] munsell_0.5.0 lifecycle_0.2.0 scatterplot3d_0.3-41 [46] stringi_1.5.3 yaml_2.2.1 clusterGeneration_1.3.4 [49] MASS_7.3-53 grid_4.0.2 blob_1.2.1 [52] parallel_4.0.2 crayon_1.3.4 lattice_0.20-41 [55] haven_2.3.1 hms_0.5.3 tmvnsim_1.0-2 [58] knitr_1.29 pillar_1.4.6 igraph_1.2.5 [61] fastmatch_1.1-0 reprex_0.3.0 glue_1.4.2 [64] evaluate_0.14 BiocManager_1.30.10 modelr_0.1.8 [67] deSolve_1.28 vctrs_0.3.4 cellranger_1.1.0 [70] gtable_0.3.0 assertthat_0.2.1 xfun_0.17 [73] broom_0.7.0 tidytree_0.3.3 coda_0.19-3 [76] viridisLite_0.3.0 aplot_0.0.6 rvcheck_0.1.8 [79] ellipsis_0.3.1 0.4 License This manuscript is distrubuted under a Creative Commons Attribution-NonCommercial-NoDerivs 3.0 License. References "],
["intro.html", "Chapter 1 Introduction 1.1 History of the field 1.2 Core concepts 1.3 A unified perspective on phylogenetic studies 1.4 Applications 1.5 Additional resources", " Chapter 1 Introduction Phylogenetic biology is the study of evolutionary relationships, and the use of those relationships to study other aspects of biology. 1.1 History of the field At the dawn of the field, in the second half of the 19th century (Darwin 1859; Haeckel 1897), phylogenetic biology was largely a speculative endeavor. People looked at similarities and differences across organisms, and made hypotheses about the evolutionary relationships that would give rise to those patterns. It wasn’t until the second half of the 20th century that explicit methods were developed to infer phylogenetic relationships (Hennig 1966). This ushered in decades of accelerating phylogenetic methods development that continues to this day. The introduction of explicit model based approaches to phylogenetic inference was particularly influential (Felsenstein 1981). These new methods were highly computationally intensive, but fortunately their rise paralleled the rapid development and widespread availability of computers. Beginning in the late 1980s, molecular data became widely used for building phylogenies of extant organisms with data from fragments of a few genes. Starting in about 2010, new generations of high-throughput sequencing technology made it possible to collect sequences for thousands of genes from a broad diversity of organisms in a single study, and right now we are in the earliest days of building phylogenies from broadly sampled high-quality chromosome-level genome assemblies. Phylogenetic Biology has always been concerned with figuring out evolutionary relationships. This domain of inquiry is referred to as phylogenetic inference. It has been vital to improved classification of species (phylogenetic taxonomy), reconstructing key features in the evolutionary history of many groups of organisms, and is extremely interesting to those who know the organisms well. Once so many advances were made in building trees, many investigators have of course asked themselves, “Now what do I do with this tree?” There has also been a growing recognition that many questions require knowing evolutionary relationships, even if those evolutionary relationships are themselves not of central interest to the investigator. This has led to the rise of another domain often referred to as phylogenetic comparative biology. Instead of ending with trees, as many phylogenetic inference projects do, phylogenetic comparative projects usually start with trees and use them to study the evolution of traits. Comparative questions include whether there is evolutionary covariance between traits, or shifts in rates of evolution along particular edges (also referred to as branches). Phylogenetic comparative methods have become an increasingly large part of the field. Though phylogeny initially sprung from the field of comparative morphology, and much of the initial focus was on building and analyzing trees with morphological data and using them to study the evolution of morphology, the field has rapidly expanded to encompass many other categories of data. Even so, morphology continues to be vital to building phylogenies in many contexts, including when fossils are available. While most phylogenetic inference is now based on molecular data, phylogenetic comparative methods are routinely applied to all sorts of data and questions. Phylogenetic comparative methods now play important roles in the study of physiology, ecology, genomics, medicine, and most other parts of biology. Phylogenetics is no longer a strictly macroevolutionary field. Some of the most exciting work in recent years has been at the interface of population genetics and phylogenetic biology, helping to unify our perspectives on micro and macroevolution. Phylogenies are now also routinely used to study the evolution of genes and other molecular characters, and also to dive into extremely recent and fast evolutionary processes within species, such as virus pandemics. 1.2 Core concepts There are a few concepts that are fundamental to understanding phylogenetic analyses (Figure 1.1A). These include: The topology of the phylogeny. This is the structure of the evolutionary relationships. It can be thought of the branching order of a tree. The lengths of the edges, also known as branches, in the phylogeny. Length can mean different things, such as time elapsed or amount of expected evolutionary change. Characters. The organism attributes under consideration. These include things like leg length, geographic location, a particular site in a particular gene, a physiological attribute, or a feature of genome organization. Character states. The particular values that can be taken by different individuals for specific characters. If leg length is a character, a leg length character state could be 4.3 mm. For a site in a DNA sequence, a character state could be C, G, T, or A. Models. These are hypotheses about how characters evolve. They take a mathematical and statistical form. For example, a model could describe the covariance between evolutionary changes in different characters, or be a set of functions that describe the probabilities of specific state changes along an edge. Models are abstract representations of biological processes. They are deliberate simplifications that allows us to explicitly describe what we think the most important features of change are. We can make models as simple or complex as we like, but the more complex they are the more information we need to use them effectively. Model parameter values. These are the specific values for terms in the model. In a model that indicates covariance between characters, the specific values in such a covariance matrix are model parameter values. If you have a set of functions that describe the probability of changing between particular states for a character, the model parameters include the rates in those functions. In order to make informative comparisons across species, both for inferring phylogenies and for phylogenetic comparative analyses, we need a unified ontological framework to refer to the same characters and character states in different organisms. This correspondence is provided by the concept of homology. Homology is a hypothesis that the same attribute is present in different entities because that attribute was present in their shared ancestor. Homology is a deceptively simple concept that can sometimes be devilishly difficult to define, test, and apply [wagner2014]. Figure 1.1: (A) The primary components of a phylogenetic analysis. This mammal phylogeny and edge lengths are from http://vertlife.org. The organism silhouettes are from http://phylopic.org/. (B) Different analyses tend to take different approaches to these components. 1.3 A unified perspective on phylogenetic studies Phylogenetics is such a diverse and quickly growing field that sometimes studies can seem to be more different from each other than they are. This is a shame, as it is a lost opportunity to share ideas across domains in the field and to apply what is learned in one context to another context. Fortunately, phylogenetic biology has a strong conceptual foundation that provides a unified perspective on phylogenetic studies (Hohna et al. 2014). Once you have this in mind, you can better see the relationships between what may initially appear to be very different methods, questions, and analyses. Let’s revisit the list above, and rearrange it a bit. We have: Topology Edge lengths Characters Character states of tips Character states of ancestors Model Model parameters The investigator can generally take one of three approaches to each of these things (Figure 1.1B). They either: Clamp the value according to information in hand, such as their own data or the results of a previous study Estimate the value Don’t care about the value Many phylogenetic inference studies use expert knowledge to define and clamp the characters, run some preliminary analyses to evaluate and then clamp the model, and clamp the character states at the tips according to the observed data such as gene sequences. They then estimate the topology, edge lengths, character states of ancestors, and model parameters. They then throw away the estimates of ancestral character states and model parameters, and present the topology and edge lengths as the result. The end result is that you get a tree of the inferred evolutionary relationships between your organisms of interest. Many phylogenetic comparative analyses take the same approach to characters and observed character states at the tip (both clamped), and ancestral character states (estimated, but discarded). They then take a different approach to the remaining items. They clamp the tree and edge lengths according to the results of an earlier phylogenetic inference, evaluate different models, and estimate model parameters. The models and model parameters are then the presented results. They would report, for example, that a model that allows for shifts in rates of evolution along different edges is a better fit than a model that doesn’t, or provide estimates of the evolutionary covariance between traits. Other studies apply the three approaches (clamp, estimate, don’t care) in different ways across the phylogenetic study. Some combinations are very common, others very rare. Some have yet to be explored at all. There are a few reasons for this variation. One is historical. Some combinations became widespread early on and stayed that way as later studies were created in the image of earlier studies. Another reason is methodological. Some combinations are rare or nonexistent in practice because they require methods development that hasn’t been done yet. Data limitations are another big issue. It takes more data to estimate more things. As you get more data, you can unclamp more things. And the biggest limitation is often computational. Phylogenetic analyses are often computationally expensive, and this can quickly become limiting. This is often the ceiling in practice, but more efficient software tools, improved methods, and new data are all helping to make analyses more tractable at the same time that more computer power is becoming available to more investigators. Once you dig in, the “don’t care” case is surprisingly interesting. Sometimes if you don’t care about something, you don’t need to estimate it. But usually you do need to estimate it to get what you do care about, and then you just throw away the result. Things that you aren’t specifically interested in but that you need to estimate to figure out what you do want to learn are referred to as nuisance parameters. Some nuisance parameters aren’t even retained by software, but others are. I I mean “don’t care” in the specific sense that these entities aren’t part of your primary question. You should very much care whether your nuisance parameter estimates are sensible since other results depend on them, and you should examine them whenever you can. Some studies differ only in which estimates are kept and which are thrown away. One person’s nuisance is another’s bread and butter. One study may keep ancestral character states and discard model parameters, and another study may run essentially the same analysis but discard ancestral character states and keep model parameters. 1.4 Applications With this framework in mind, let’s take a look at a sampling of recent phylogenetic studies. Nextstrain provides a frequently updated phylogeny of sars-cov-2, with associated data on geography, sampling time, and other factors (Hadfield et al. 2018). This has been critical to understanding and monitoring the sars-cov-2 pandemic, and intervening to disrupt transmission. They are using observed character data at the tips (virus genome sequences) to estimate topology, edge lengths, and model parameters. Myxozoa are enigmatic parasites that live in fish. They have very few morphological traits that show clear homology with other animals. So Sally Chang, Paulyn Cartwright, and colleagues used phylogenetic inference to examine their relationships to other animals, and found strong support for their placement within Cnidaria (Chang et al. 2015). My own lab wanted to see if the evolution of gene expression is more rapid after gene duplication than after speciation (Dunn et al. 2018). We found no evidence for such a difference. We used the results of previous studies to clamp gene phylogenies and gene expression character states at the tips, and estimated ancestral expression states to examine sifts in expression along particular edges. Viburnum is a group of plants with wide distribution in many different habitat types. Michael Landis spearheaded a collaborative project between the Edwards and Donoghue labs here at Yale EEB to understand how Viburnum first diversified in Asia during the Eocene and then spread across the globe (Landis et al. 2020). They clamped the character states at the tips based on gene sequence data, morphology, and geographic range, developed innovative methods to simultaneously estimate the phylogeny, edge length, and ancestral geographic ranges. This is the vanguard of new approaches that simultaneously consider multiple categories of data rather than bolt together multiple independent methods that estimate one thing at a time. This is a very exciting time in phylogenetic biology. For many years most studies followed a few basic templates. With the development of new phylogenetic methods, new tools to collect high throughput character data, and a growing interest in phylogenetic questions, the field is now in its most interesting stage of development and application yet. 1.5 Additional resources References "],
["phylogenies.html", "Chapter 2 Phylogenies 2.1 Phylogenies are graphs 2.2 Drawing phylogenies 2.3 Some properties of trees 2.4 Rotating nodes 2.5 The meaning of edge lengths 2.6 Naming nodes and groups 2.7 Polytomies 2.8 Rooting 2.9 The information contained in phylogenies 2.10 Representation 2.11 Additional reading", " Chapter 2 Phylogenies Figure 2.1: Darwin’s depiction of the evolutionary relationships between organisms (Darwin 1859). Phylogenies represent evolutionary relationships. The only figure in Darwin’s Origin of Species (Darwin 1859) was a phylogeny (Figure 2.1), though he didn’t call it that. Phylogenies are often referred to as trees. It is an apt analogy. From the anchoring of the tree at a root, to the depiction of lineages as branches, to the presentation of tips as leaves, there is a direct correspondence. Many of the first speculative phylogenies were illustrated as actual trees, including Haeckel’s tree in the manuscript (Haeckel 1897) where he coined the term phylogeny (Figure 2.2). Figure 2.2: Haeckel’s hypothesis of the animal phylogeny (Haeckel 1897), drawn as an actual tree. Not all trees in biology are phylogenies, though. For example, hierarchical clustering of traits across species results in trees that represent similarity of species, but does not necessarily show evolutionary relationships. In some cases phylogeny and species clustering will be largely congruent, but in many cases they will not be. Hierarchical tree-like clustering is also used for things that have no evolutionary component, like similarity of responses to a drug. It is helpful, then, to be more precise about the components of a phylogeny, and what each of those parts represent. 2.1 Phylogenies are graphs in order to establish a strong foundation for thinking about phylogenies, it is helpful to turn to math. Figure 2.3: Simple graph. Nodes are represented by circles, and edges by lines. Note that this graph has a cycle (you could walk in a circle between nodes 1, 2, and 4). It is also not bifurcating. A phylogeny is a specific instance of a mathematical object known as a graph. A graph consists of nodes, often represented as circles, connected by edges, often represented by lines (Figure 2.3). Graphs are useful representations of a variety of systems. For example, nodes could be people, and edges family relationships, connections in a social network, or financial transactions. Because it makes it easier to learn from adjacent fields when using mathematical conventions that are shared across fields, I will tend to use mathematical notation for phylogenies rather than the classical botanical nomenclatures. I will refer to edges rather than branches, tip nodes rather than leaves, etc… Figure 2.4: Graph representing a phylogeny. The tip nodes typically represent sampled entities, like living organisms, sequenced genes, or fossils. The internal nodes are ancestors that immediately precede divergence events. The root is a special internal node that has no parent. It is acyclic (ie, there are no paths that go in circles). The graph is bifurcating– the root node has two edges that connect it to its children, the other internal nodes each have three edges (one that connects to the parent, two to children), and the tips each have one edge (that connects to their parents). Phylogeny graphs (Figure 2.4) usually have a few specific topological properties: They are acyclic. This means that there is only one possible path along edges from one node to another. It isn’t possible to go in circles. Exceptions can arise in cases of horizontal gene transfer or hybridization. They tend to be bifurcating. This means that each internal node has one parent node and two daughter nodes, and therefore three edges connected to it. This represents the biological understanding of speciation, which usually proceeds by one lineage giving rise to two lineages. They can be directed. This means that edges are not symmetric, and instead have directionality. Specifically, they denote time. The node on one end of the edge is older than the node on the other side of the edge. We therefore can refer to the nodes connected to a particular edge as the parent node and child node. A phylogenetic graph is an abstraction, and for it to be useful it is important to keep in mind what features of biology we are attempting to represent. The nodes are entities that can evolve, like organisms or genes. The edges indicate evolutionary relationships between those entities. You could imagine as, an extreme case, a graph that showed every single individual that ever existed in your group of interest, say mammals. Each edge would connect literal parents and offspring. That would be a big phylogeny, and you would never have enough information to know it all, but it does exist even if unknowable and unwieldy given our current tools. A phylogeny is a subset of that graph, where we often retain a single individual per species as the tip nodes, and retain nodes immediately preceding divergence events as the internal nodes. In this respect, a phylogeny is a subgraph of the entire history of life on Earth. Because many generations are collapsed along a single edge, parent-child node relationships in the tree don’t mean actual parent-child relationships. Parent-child nodes are often separated by millions of generations. 2.2 Drawing phylogenies Here we will work with some mammal phylogenies, mostly because their silhouette icons are so recognizable and because there are extensive phylogenies available for this group (Upham, Esselstyn, and Jetz 2019). You will rarely see a phylogeny depicted as in Figure 2.4, with a circle for every node. It gets too cluttered. Instead, it is simpler to draw just the edges (Figure 2.5), with the nodes implied at the ends of edges. The nodes are implied. Figure 2.5: Phylogeny of some mammals. Topology and edge lengths from http://vertlife.org. The organism silhouettes are from http://phylopic.org/. Note that node circles are not drawn, instead nodes are implied at ends of edges. There is considerable variation in how the same phylogeny can be drawn (Figure 2.6). This gives some flexibility in deciding what presentation is best for your particular goals, but can also create confusion because two images that look very different may in fact be of the exact same phylogeny. Rectangular layouts are the most common, because the entire edge length is along one axis of the plot. In a rectangular tree, each node is depicted as a line that is orthogonal to the edges. The confusing thing is that, because this line has the same width and color as the edges, it looks as if it is part of the edge. It isn’t though– its length is arbitrary, and it just shows which edges attach to that node. It also adds right-degree elbows where the ends of the node lines connect to the edges, forming a corner. Slanted layouts avoid the node lines and elbows of rectangular layouts, but because the edges aren’t parallel and can be at a variety of angles, it isn’t always easy to read edge lengths on them. Circular layouts place the root at the center, and the tips around the circumference. This is a compact representation that works well for very large phylogenies. Figure 2.6: The same tree as above, layed out in several different ways. 2.3 Some properties of trees In a fully bifurcating phylogeny with \\(n\\) tip nodes, the following will be the case: There are \\(n-1\\) internal nodes. For example, Figure 2.4 shows a phylogeny with 4 tip nodes (labeled 1-4) and 3 internal nodes (labeled 5-7). The total number of nodes (tip nodes and internal nodes) is therefore \\(2n-1\\). Each tip node has a single edge, which connects it to its parent node. The root node, which is a special internal node that is older than all other nodes, has no parent edge, so it has only two edges. These connect it to its immediate descendant nodes (its children). All internal nodes in the tree other than the root have three edges - one connected to a parent node, and two connected to child nodes. Since every edge in the tree has a single child node, and each node in the tree except for the root as a parent edge, the total number of edges in the tree is \\(2n-2\\). The function for the number of possible rooted phylogenies for \\(n\\) tips is: \\[\\begin{equation} f\\left(n\\right) = \\frac{(2n-3)!}{2^{(n-2)}(n-2)!} \\tag{2.1} \\end{equation}\\] This gets big really, really fast as \\(n\\) increases. For a phylogeny of 5 tips there are 105 possible topologies. For a phylogeny of just 10 tips there are already 34,459,425 possible topologies. For a phylogeny of 50 tips there are \\(2.75\\times10^{76}\\) possible topologies. This very large number of possible trees is a major challenge when it comes to inferring phylogenies from data – it is impossible to consider all possible topologies. 2.4 Rotating nodes One of the most important things to keep in mind when interpreting a phylogeny is that the order of the tips doesn’t convey any information. You can rotate any internal node, changing the order of the tips, and you still have the exact same phylogeny, just drawn a different way (Figure 2.7). The topology remains unchanged. It’s the connections that tell us about the relationships. JD Laurence-Chasen, a former student in my invertebrate zoology course, made an excellent video about this – https://vimeo.com/148794860 . The major implication of this is that you should never read a phylogeny across the tips to see, for example, which species are more closely related. You always need to look at the structure of the phylogeny itself. Figure 2.7: The exact same phylogeny, drawn a few times with different node rotations. 2.5 The meaning of edge lengths Another type of variation in phylogeny depiction is the meaning of edge length (Figure 2.8). A phylogeny where edge lengths are scaled to time is known as a chronogram. Chronograms of organisms all sampled at the same time will be ultrametric, ie the tip nodes will be flush. If tips are sampled at different times, for example when including fossils or sampling a rapidly evolving virus at different time points, they will not be ultrametric. In many cases we don’t have the information needed to scale edges to time, which requires fossil calibrations. Most published phylogenies therefore scale the edges according to the expected amount of evolutionary change in the characters under consideration. The longer the edge, the greater the expected change. The rate of evolution usually varies a bit across edges, so phylograms are not usually ultrametric. Sometimes we are only interested in, or only have information about, the topology of the phylogeny. In this case we can draw the edges whatever length we want, and we call the phylogeny a cladogram. Cladograms can also be useful for showing annotations on edges in phylogenies with a wide variation in edge lengths, since there might not be enough room to write labels on very short edges. It is always good practice whenever you show a phylogeny to indicate whether it is a chronogram, phylogram, or cladogram. Unfortunately, this is inconsistent in the literature, and not always clear from the figure legend or text. If you aren’t sure what edge length means it is best to just ignore edge lengths and treat the phylogeny as if it were a cladogram. Figure 2.8: Several types of trees. In a chronogram, edge lengths are scaled according to time. In a phylogram, edge lengths are scaled according to expected amount of evolutionary change, which can differ across characters and edges. In a cladogram, the edge lengths have no meaning. 2.6 Naming nodes and groups One of the most useful applications of phylogenies is to concisely refer to groups of organisms in light of their evolutionary history. A convenient way to designate groups of organisms is by their most recent common ancestor (MRCA). One of the core concepts in phylogenetic biology is the clade - a group of tips that includes their MRCA and all of its descendants. A group is said to be monophyletic (Figure 2.9A) if it satisfies these criteria (you don’t need to use the double descriptor “monophyletic clade”, since a clade is by definition monophyletic). Since internal nodes are included in this definition, you can think of a monophyletic group as a subtree that is formed by clipping the edge just below the MRCA. Figure 2.9: (A) A monophyletic group, i.e. a clade. (B) A polyphyletic group. (C) A paraphyletic group that does not include the rabbit. Any internal node in a rooted phylogeny can be described as the MRCA of two or more tips. You can therefore use sets of tips to designate a particular internal node, and then use that node to define a clade. For example, we could clearly designate mammals as all the descendants of the MRCA of humans and duck billed platyups. This is a very compact and unambiguous way to name groups of organisms. In fact, an entire biological nomenclature has been built with phylogenetically defined names like these (deQueiroz and Cantino 2020). Not all groups are monophyletic. For example, the group consisting of people and mice to the exclusion of rabbits is not monophyletic. Their MRCA is easy enough to find, and once found it is clear that not all descendants of this node are included in the group. Slightly different terminology is used for such groups depending on how we think about internal nodes and edges. If we think of this set of non-monophyletic tips as isolated tips, to the exclusion of the MRCA, then we say the group is polyphyletic (Figure 2.9B). If we think of it as including the MRCA but excluding all the other tips descended from that MRCA that are not in the group, then we call it paraphyletic (Figure 2.9C). In extreme cases the distinction is clearer. For example, if you have a large group of 100 species that is monophyletic except for the exclusion of a couple species nested well within the group, then it would usually be referred to as paraphyletic. If you were referring to a small group of tips scattered across a very large phylogeny with hundreds of tips, then it would usually be referred to as polyphyletic. 2.7 Polytomies Some phylogenies are not strictly bifurcating. An internal node with more than two edges connecting it to descendants is called a polytomy (Figure 2.10B-D). This can be to uncertainty about branching order (a soft polytomy) or multiple divergence events in very quick succession, giving rise at effectively the same time to more than two lineages (a hard polytomy). A phylogeny that consists entirely of a single polytomy is said to be entirely unresolved – it has no topological information. When laid out in a rectangular format, it looks like a comb (Figure 2.10D). When laid out in a slanted format it looks like a star. So you will hear fully unresolved trees referred to as comb or star phylogenies. Figure 2.10: (A) The fully resolved mammal tree used in other figures. (B-C) Different polytomies created in this tree by collapsing some groups. (D) A fully unresolved comb tree. 2.8 Rooting All the phylogenies we have seen so far are rooted – we know what the oldest point is in the tree, and call it the root node. This special internal node has no edge connecting it to a parent node, and all other nodes in the phylogeny are its descendants. One consequence of having a rooted tree is that we know the direction of time along each edge – time proceeds from the root to the tips. This provides a clear parent-child relationship between nodes at the ends of each edge. Not all phylogenies are rooted. Sometimes we just don’t care – some questions and methods don’t depend on where the root is, so we don’t have to bother placing it. Sometimes we just don’t know – placing the root in a phylogeny takes information that sometimes we don’t have. There are many phylogenetic studies focused on identifying the location of the root in various groups of organisms, this is often an interesting and important question. Even when we don’t know where the root of a phylogeny is, we often want to talk about other aspects of the tree, such as the topology and edge lengths. This means we need to think about how to think about unrooted phylogenies. There are some basic things we can’t take for granted in an unrooted phylogeny. We don’t, for example, know which way time goes along the branches. We don’t know which internal nodes are child nodes and which are parent nodes. We don’t know which of the edges attached to an internal node connect to older nodes and which to younger nodes. Figure 2.11: These four cladograms have the same tips and same topology, only their layout differs. (A) The first layout is unrooted. The other three are rooted on the red node (B), blue node (C), and orange edge (D). These colored elements are in the exact same topological positions in all trees. When the tree is rooted on the red or blue nodes, the base of the tree is a polytomy since these nodes have three edges attached to them. No nodes are added or removed when rooting on a node. When rooting on the orange edge, a new unrooted node is added along the edge. This new node is bifurcating. The root could fall at any point in an unrooted phylogeny, either along an edge or right at an internal node. You can think of rooting a phylogeny as grabbing the point that you think is the root and dragging it until all the edges point away from it (Figure 2.11B-D). If you grab at some point along an edge (Figure 2.11D), this creates a new node that is the root. This new root node has two edges connecting it to descendants (these two edges arise by splitting the single edge along which the root was placed). Since it has no edge connecting it to a parent, it differs from other internal nodes in having only two edges connected to it (instead of three, or more in the case of polytomies). The end results of rooting along a edge is that you add a node to the phylogeny and the root is resolved (not a polytomy). Things are a bit different if you root at an existing internal node (Figure 2.11B-C). Because the existing node becomes the root, the number of nodes in the tree remains unchanged. So far so good. But since internal nodes in a bifurcating tree all have three edges connected to them, when an internal node becomes the root the root is a polytomy. This seems like a pain, so why not always root along an edge? There are a few reasons. One is that rooting along an edge requires that we pick a specific point along the edge where the root goes, for example in the middle or somewhere else. That decision can take information that we don’t have. Another reason is that the creation and destruction of nodes associated with rooting along edges gets cumbersome and problematic, especially when there are specific data associated with internal nodes. What information can we use to root a phylogeny? There are a couple approaches. One is to pick the midpoint – the point farthest from any tips – as the root. If evolution proceeded at a perfectly uniform rate this could work well, but in practice rates of evolution are too variable across lineages for this to give a reliable result. The more common approach to rooting a phylogeny is to use an outgroup (Figure 2.12). If the ingroup is the group of organisms you are interested in (e.g., mammals), the outgroup is a set of animals that you strongly believe do not fall within the ingroup. If you place the root anywhere in the outgroup, then the most recent common ancestor of the ingroup will be the root of the ingroup. Rooting this way works better when a larger number of outgroup species are considered, and the outgroup species include the organisms most closely related to the ingroup. Including too few outgroups is one of the most common mistakes in published phylogenies. Figure 2.12: The root of the mammal tree is shown in red. (A) Unrooted layout. (B) Rooted layout. (C) Rooted layout, including outgroup. The root for the whole tree, shown in blue, is placed in the outgroup. The node where the ingroup is attached to the rest of the tree is the ingroup root. In this case, that is the red mammal root. Always be careful interpreting root position when looking at a published phylogeny. Unrooted phylogenies are often drawn is if they are rooted, often by picking a random rooting point or making a good guess of where the root is. This is in part because rooted phylogeny figures tend to be easier to read than unrooted figures. If the figure legend or text doesn’t state how the tree was rooted, best to assume that it wasn’t rigorously rooted if this is critical to the analyses at hand. 2.9 The information contained in phylogenies Thinking about phylogenies as graphs gives us very explicit ways to think about what information can be contained in a phylogeny. In the fundamental graphical sense, a phylogeny is a pair of sets – a set of nodes and a set of edges – and annotations of those entities. The topology of the phylogeny is the way in which nodes are connected by edges. If there are different connections in two phylogenies, then they have different topologies. If the annotations differ but the connections are the same, then the topologies are the same. Sometimes we know more and sometimes less about the topology. A fully resolved bifurcating phylogeny, where every internal node has two children, contains maximal information about the topology. A completely unresolved star phylogeny contains no information about topology. Node annotations can include: Labels. On tip nodes these could be species names, gene names, or museum accession numbers for particular specimens. For internal nodes, they could be clade names (eg Mammalia). Character states. The presence or absence of particular attributes (like hair), or the particular nucleotide at a particular spot in a particular gene (CGTA). Often the character states for tip nodes are observed from data and the states of internal nodes are estimated. There are exceptions, though. One can, for example, estimate the states of tips for which no observations are available. Geographical locations. Whether the node is the root. Edge annotations can include: Length. The value and unit of length can differ, for example it can time (as in a chronogram) or expected amount of change in a particular set of characters (as in a phylogram). Directionality. An indication of which direction time goes in along each edge. This only applies in the context of a rooted phylogenies. Events. These could include a character change (such as the gain of a placenta) or a geographical change (such as an intercontinental dispersal event). Nodes at eache end of an edge need not be different in the relevant trait to have change events along the edge. For example, at a particular gene site a parent and a child node could both have an A. There could be two or more events along the edge that are compatible with this pattern, for example a change from A to C and then a change from C back to A. Edge frequencies.This is how topology support values, such as bootstraps and posterior probabilities (which we’ll discuss later), are stored. Not all phylogenies have all this information. The minimum possible information a phylogeny could contain is just the number of tips. With this, you could draw an unresolved, unlabeled cladogram (Figure 2.13A). You could then start layering information onto that phylogeny. For example, you could next add images denoting the species at the tips (Figure 2.13B). That tells you what species are in the phylogeny, but nothing about how they are related. Next you could add internal nodes and edges that indicate the topology of the phylogeny (Figure 2.13C). Once you have topology, you could display edge attributes. For example, you could scale the edge lengths by time (Figure 2.13D). At each step in this process of layering on information, the phylogeny is compatible with a very large set of possible phylogenies. At one extreme, Figure 2.13A is compatible with any phylogeny with any edge lengths for any 11 species or organisms or genes. Each added piece of information narrows that subset. When we label the tips as in Figure 2.13B, it is compatible with any phylogeny with any edge lengths for those specific species. And so on. More information provides more specificity. We could go well beyond Figure 2.13D, for example by labeling internal nodes or showing character states. The amount of information in a phylogeny varies greatly depending on a variety of factors, including what information is available, what the question at hand is, and what makes the most sense for the focused description of the biology at hand. One investigator may go to great lengths to calibrate edge lengths, for example, while another couldn’t care less about edge lengths and is only interested in topology. Figure 2.13: Adding information to a phylogeny makes it more specific. 2.10 Representation So far we have focused on phylogenies in the abstract sense as mathematical graphs and their associated annotations, and in the concrete sense as tree-like drawings that represent these relationships. To work with trees of any significant size, we need to also represent them computationally. How can you store and manipulate a whole tree and all its associated annotations? One way is to store a text representation of the tree. This is conveneint because text files are easy to work with, and can be viewed and edited with a variety of existing text editors. Newick, a phylogenetic data format ironed out over dinner at Newick’s Lobster House, does exactly this. The newick format is widely used for storing phylogenies in text files, and is supported as a way to read and write trees by almost every phylogenetic software tool. The basic idea is to designate each clade within a pair of parentheses. # Define the newick text that includes the tip labels and tree topology newick_text = &quot;(((A,B),(C,D)),E);&quot; # Create an ape phylo object from the tree text phylo_tree = read.tree( text=newick_text ) # Plot the newick_tree phylo object using the ggtree library ggtree(phylo_tree ) + # Draw the tree geom_text2(aes(label=node), col=&quot;red&quot;, nudge_x=0.1 ) + # Add the node numbers geom_tiplab( aes(label=label), offset=0.3, col=&quot;blue&quot;) + # Add the tip labels geom_nodepoint(col=&quot;red&quot;) + # Add points on nodes geom_tippoint(col=&quot;red&quot;) Figure 2.14: Defining and drawing a Newick tree. Tip labels are blue, nodes and node numbers are red, and edges are black. In Figure 2.14, you can see how to define a newick tree, convert it to a different type of representation, and then draw that. Most of the figures in this text were made using similar code. Considering just the newick specificaiton of the tree, \"(((A,B),(C,D)),E);\", you can see it built up as a series of clades. The inner-most sets of parentheses define two clades, (A,B) and (C,D). The next set of parentheses out indicates that these two clades together form a larger clade, ((A,B),(C,D)). Finally, the outermost parentheses indicate that the clade ((A,B),(C,D)) is sister to E. Commas separate sisters within clades, and the whole thing is finished off with a semicolon. The format also allows for labels of internal nodes, and the specification of branch lengths. Joe Felsenstein wrote an interesting description and history of the newick format, which includes details on how to store other types of information in the file format. As versatile and simple as newick is for storing trees in files, it isn’t great for storing trees in computer memory where you want to do things with them. To build and analyze trees it is better to have a format that has a more direct representation of nodes, edges, and their annotations. This allows us to directly encode the information noted in the section The information contained in phylogenies, and to readily extend the data objects as needed. The most widely used format for storing phylogenies in the R programming language is as a phylo object from the excellent ape library (Paradis et al. 2020). The read.tree() function in the code block above creates a phylo object called phylo_tree based on the phylogeny we specified as text and named newick_tree. In a phylo object, each node of a phylogeny has a unique number. The first consecutive node numbers, from 1 to \\(n\\) where \\(n\\) is the number of tip nodes, are allocated to the tip nodes. The internal nodes are numbered consecutively from there, which in a bifurcating tree will be nodes \\(n+1\\) to \\(2n-1\\). The assignment of the node numbers within these ranges is arbitrary, there is no guarantee for example that the same internal node will ahve the same number each time the tree is read. The numbers of the nodes that were given when we created the phylo object from the newick text are shown in red in Figure 2.14. Below we take a quick peek inside the phylo object we created above. The intent isn’t to learn how to manipulated trees in R quite yet, but to just show you how trees can be stored in computer memory. First, let’s take a look at the structure of the phylo object to see what variables it contains within it: str( phylo_tree ) ## List of 3 ## $ edge : int [1:8, 1:2] 6 7 8 8 7 9 9 6 7 8 ... ## $ Nnode : int 4 ## $ tip.label: chr [1:5] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; ... ## - attr(*, &quot;class&quot;)= chr &quot;phylo&quot; ## - attr(*, &quot;order&quot;)= chr &quot;cladewise&quot; We can see that there are three slots (each designated with a $) within this phylo object. Nnode is just the number of internal nodes. The real magic is edge, which encodes the topology of the tree. It is just an array with one row per edge, and two columns. The value in column 1 is the number of the node that is the parent of the edge, and the value in column 2 is the number of the node that is the child of the edge. Here are the complete contents of the edge slot: phylo_tree$edge ## [,1] [,2] ## [1,] 6 7 ## [2,] 7 8 ## [3,] 8 1 ## [4,] 8 2 ## [5,] 7 9 ## [6,] 9 3 ## [7,] 9 4 ## [8,] 6 5 So, in this case edge number 1 (the first row) connects node 6 to node 7. Indeed, we can see just such an edge in Figure 2.14. Try to identify each of the other edges in the array in the tree figure. You can discern all sorts of things about the tree from this simple array. The tips are nodes that are in column 2 but not in column 1 (since they aren’t parents of any other nodes). The root is the node that is in column 1, but not in column 2 (because it doesn’t have a parent). If a node occurs in column 1 more than twice, then it is a polytomy (because it has more than two edges connecting to child nodes). Note that this data structure is intrinsically rooted - there is a parent-child relationship set up between the nodes at each end of each edge. But you can still use it to store unrooted trees by picking an arbitrary internal node as the root, and just keeping track of the fact that you don’t know where the root is. There is one other important piece of information that we specified in the newick files - the tip labels. Those are located in another slot within the phylo object: phylo_tree$tip.label ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; We can see that this is just a vector of labels. They correspond to the labels of nodes one through five, all the tip labels, in consecutive order. That’s it. That’s all the information we specified in the newick file, all the information in the phylo object, and all the information that is needed to draw Figure 2.14. The newick tree is easy to store and manipulate with simple text tools, the phylo object is a powerful and flexible way to represent the tree in computer memory, and the figure is easy to read at a glance. 2.11 Additional reading I used ggtree (Yu and Lam 2020) to draw the trees in this chapter. If you are interested in learning more about these tools, see: The ggtree book - https://yulab-smu.github.io/treedata-book/index.html ggtree vignettes - https://bioconductor.statistik.tu-dortmund.de/packages/3.1/bioc/vignettes/ggtree/inst/doc/ggtree.html References "],
["simulation.html", "Chapter 3 Simulation 3.1 Models 3.2 A simple model of evolution 3.3 Generalizing the simple model 3.4 Expanding the models 3.5 Plugging some numbers into the expanded model 3.6 Simulation along a single edge 3.7 Scaling from a single edge to a whole tree 3.8 Scaling from a single site to multiple sites 3.9 Concluding thoughts 3.10 Additional resources", " Chapter 3 Simulation Here we will build the machinery to implement models of DNA evolution. Our first application of these models will be to simulate data. 3.1 Models Models are representations of processes. They are idealized in the sense that they are deliberately simplified, and they are abstractions in the sense that they leave out things that aren’t thought to be important. As Peter Godfrey-Smith notes (Godfrey-Smith 2013, 21), “Abstraction, to some degree, is inevitable; you can’t include everything. Idealization, in contrast, is a choice.” For some applications, it doesn’t matter if model structure reflects actual underlying processes, as long as it generates useful output (Breiman and others 2001). For example, if data scientists at a large retail chain are trying to predict how much toothpaste they need to stock at each store, they likely don’t care if their models properly consider purchasing rates and all the other things that impact stock, so long as the the model does a reasonable job of making reasonable predictions. In science, though, we often care very much about the model because many of our questions have to do with the mechanisms that underlay the processes we are modeling. We don’t just want models that give us the right answer, we often want models that give us the right answer for the right reasons. Statisticians often note that “All models are wrong but some are useful”, a common aphorism expanded from a quote by Box (1976). The goal of a model isn’t to be “right” in the sense of being a perfect explanation of data. Real data are far too complex for any model to do this. Instead, the most useful models strike a trade-off between simplicity and adequacy. They are as simple as possible, while adequately describing the phenomenon of interest. Adequacy is often in the eye of the beholder – one scientist will be perfectly happy with a model that makes reasonable rough approximations of a system, another scientist may be interested in second and third order effects for which more complexity is needed for adequate explanation. Cartography is an interesting analogy for the way we will use statistical models. A “perfect” map would basically be a copy of the whole world, which wouldn’t be that much more useful than the world itself already is for many of the things you would like to do with a map. So all maps are simplifications (Figure 3.1). The simplification is often what makes the map useful. Figure 3.1: Four maps of the Yale campus, varying in complexity and focus. (A) A satellite image of New Haven, including much of Yale campus, from Google Maps. This image has a very large amount of information. (B) A street map of the same region, also from Google Maps. It has less information, but is more useful for some tasks such as navigation. (C) An even more simplified map, focused on showing the Yale Shuttle routes. (D) The New Haven property map of the region around Osborn Memorial Laboratory, showing property lines and plot numbers. Like (C) it is simple, but reflects different decisions about which information to discard or retain. This figure is inspired by the London maps that David Swofford uses in his own talks to make the same points. Let’s examine one of the most common models, the linear model: \\[\\begin{equation} y = mx+b \\tag{3.1} \\end{equation}\\] Here, \\(y\\) and \\(x\\) are variables. The model posits a linear relationship between \\(x\\) and \\(y\\), that is that if you plot their correspondence in a plane you will get a line. \\(m\\) and \\(b\\) are model parameters. \\(m\\) is the slope of the line – it captures how much change there is in \\(y\\) for each unit of change in \\(x\\). \\(b\\) is the intercept – it is the value of \\(y\\) when \\(x=0\\). Figure 3.2: A linear model with \\(m\\)=0.5 and \\(b\\)=1. There are a variety of useful things we could do based on these relationships between the model, model parameters, and values. Let’s consider \\(x\\) to be a variable that tell us something about the past and \\(y\\) to be a variable that tell us something about the present or future. Use cases then include: If we clamp the model (linear) and model parameters (specific values of \\(m\\) and \\(b\\)) according to prior knowledge, and clamp \\(y\\) according to observed data, we can estimate \\(x\\). In this case the model is like a time machine that allows us to look into the past. If we clamp the model (linear) and variables (\\(x\\) and \\(y\\)) according to prior knowledge, we can estimate model parameters \\(m\\) and \\(b\\). In this case the model is like an instrument that allows us to peer inside processes based on their inputs and outputs. If we clamp the model (linear) and model parameters (specific values of \\(m\\) and \\(b\\)) according to prior knowledge, and clamp \\(x\\) according to observed data, we can estimate \\(y\\). In this case the model is like an oracle that predicts the future. If we clamp the model (linear) and model parameters (specific values of \\(m\\) and \\(b\\)) according to prior knowledge, and clamp \\(x\\) according to values we make up, we can simulate \\(y\\). In this case the model is like a world-builder that tells us what we would expect to see under the specified conditions. This is very helpful for getting a sense of whether our models are working well (Do they generate results that look like what we see?), examining counterfactual situations that don’t exist, or building datasets to test software tools. There are some deep connections here. For example, predicting the future is basically just simulating the future based on our model and what we already know about the past and present. The models that we will use in phylogenetic biology tend to be more complex than the linear mode, but this general perspective of clamping and estimating different things still holds. 3.2 A simple model of evolution Let’s start with a simple model of DNA evolution. At first we will also consider only a single nucleotide position along a single edge in a phylogeny (Figure 3.3). The goal is to build an intuitive integrated understanding of the mathematical and statistical relationships among: Model structure Model parameters Edge length State at the start of the edge (the nucleotide at the parent node) State at the end of the edge (the nucleotide at the child node) Figure 3.3: Our current goal is to model the evolution of a single site in a DNA sequence along a single edge in a phylogeny. (A) An example phylogeny, with DNA sequence fragments shown at the tips and one internal node. The site under examination is in color, and the edge under examination (at the top) is thicker than the rest. (B) A closeup of the focal edge, and the state of the focal site at its ends (the parent and child nodes). (C) Multiple mutational histories that are consistent with the starting and end states shown in (B), i.e. a cange from A to C. Imagine that when the DNA is being replicated, most of the time the appropriate nucleotide is incorporated. Some fraction of the time, at rate \\(\\mu\\), an event occurs where the appropriate nucleotides is replaced with a random nucleotide instead. In our model, the probability of selecting any of the nucleotides during one of these random replacement events is uniform (picking a C is just as probably as picking a G, for example), and the new nucleotide doesn’t depend in any way on what nucleotide was there before. It is as if you had a bag containing a large number of C, G, T, and A nucleotides at equal frequencies. As you built the new DNA strand, every so often you would replace the nucleotide you should be adding with one you instead select by reaching into the bag and pick at random. Not all replacement events will result in an apparent change. Sometimes the appropriate nucleotide is selected by chance, even though it was picked at random. If, for example, the appropriate nucleotide was an A, under this model \\(1/4\\) of the time a replacement event occurs, an A is selected by chance and there is no apparent change. In such a case, there has not been a substitution (just a replacement in kind). If the A is replaced with any of the other three nucleotides we say there has been a substitution. Because three of the four possible outcomes of a replacement event result in a substitution, the substitution rate is \\((3/4) \\mu\\). Because some events result in no apparent change, substitutions are only a subset of events and the substitution rate is lower than the replacement rate. It might seem a bit odd to consider replacement events that don’t result in substitutions, but this follows naturally from a central feature we specified for the the model - the new nucleotide doesn’t depend in any way on what nucleotide was there before. If we had a process where replacements always resulted in substitutions, then excluding the replacement-in-kind events would require knowing which nucleotide should be placed so that we don’t select it. 3.2.1 Expected amount of change For the simple process described here, there are two things to consider if we want to know the amount of evolutionary change. The first is the substitution rate \\(\\mu\\), and the second is the time over which the evolutionary process acts. In our example here, that time is the length of the edge under consideration in the phylogeny. In Figure 3.4 each horizontal bar is a simulation over the same time interval (0-100 time units). Each black line on the bar is a replacement even randomly introduced by the computer according to our model. We use a different value of \\(\\mu\\) for each simulation (as indicated on the vertical axis). In the bottom bar, where \\(\\mu=0\\), there are no replacements (black bars) and therefore no substitutions (the whole bar is the same color). There are more replacement events as \\(\\mu\\) increases along the vertical axis. Figure 3.4: Each horizontal bar is a simulation of evolution of a single nucleotide position through time, \\(t\\), for a specified value of \\(\\mu\\). Each simulation starts out as an A. Black vertical lines correspond to replacement events, which don’t all lead to substitutions (a new color). As \\(\\mu\\) increases (going up on the vertical axis), the number of replacement events over the same time interval increases (Figure 3.5). This reflects the simple linear relationship \\(n=\\mu t\\), where \\(n\\) is the number of expected replacement events. Figure 3.5: The number of replacement events increases linearly with the replacement rate \\(\\mu\\). This plot is from the same simulation as that shown in Figure 3.4. The line is a linear model fit to the data. Since \\(n=\\mu t\\), and in this case \\(t=100\\), the slope of \\(n\\) on \\(t\\) is estimated to be near 100. Because of the linear relationship between the number of replacements and the product \\(\\mu t\\), rate (\\(\\mu\\)) and time (\\(t\\)) are conflated. In many scenarios you can’t estimate them independently. If there are a small number of replacements, for example, you can’t tell if there is a low rate over a long time interval, or a high rate over a short interval. Both would give the same resulting number of changes \\(n\\). Because rate (\\(\\mu\\)) and time (\\(t\\)) are so often confounded in phylogenetic questions, often the rate is essentially fixed at one and the unit of time for edge lengths is given as the number of expected evolutionary change rather than absolute time (years, months, etc). You will often see this length as the scale bar of published phylogenies (Figure 3.6). The exception is when you have external information, such as dated fossils, that allow you to independently estimate rates and edge lengths in terms of actual time. Sometimes deconfounding \\(\\mu t\\) isn’t important to the primary question of the investigator, sometimes it would be nice to know but can’t be done, and other times (such as in papers that date trees) it is the central question. Figure 3.6: A published phylogeny (Zapata et al. 2015) with a scale bar indicating branch length in terms of the expected amount of evolutionary change, rather than absolute time. 3.2.2 Expected end state The machinery above shows how a model can clarify the way we think about the expected amount of change along an edge. Many times, though, we want to know what the probability of a given end state is given a starting state, a model, and the amount of time elapsed. One way to anchor such a question is to think about the extremes - what do we expect after a very small amount of change (either a short time or a slow rate of change, or both), and what do we expect after a large amount of change? The situation is most clear after a small amount of change - we expect the end state to be the same as the starting state. If we start with an A, for example, if there is very little change we expect to end with an A (Figure 3.7, left side). In this situation, the starting state tells us a lot about the end state. Not much else matters. What should we expect, though, if there has been a large amount of change? Can we know anything at all? It turns out that we can. If there have been many replacements, one after the other, than the initial starting state doesn’t matter because whatever was there initially will probably have been replaced multiple times. It is as if had been erased and written over. If the starting state doesn’t contain information about the end state, what does? Since replacements are coming from the bag that you are picking the nucleotides at random from, that bag has information about the expected states after a large number of changes. Given enough evolutionary time, our simple model will lead the expected frequency of each nucleotide in the evolving sequence to be the same as their frequencies in the bag. Since we specified that you have the same chance of grabbing any nucleotide from the bag, eventually the probability of having each of the our nucleotides is the same, 25% (Figure 3.7, right side). If you started with a sequence that had an A and let it evolve 100 times, after enough evolutionary time had passed to reach equilibrium you would expect to get 25 C’s, 25 G’s, 25 T’s, and 25 A’s. Figure 3.7: Stacked bar plots indicating the frequency of each nucleotide after simulated evolution for a specified amount of time. The rate of evolution is \\(\\mu=0.050\\). There are 1000 replicate simulations for each value of time. At time \\(t=0\\) (no evolution), the end result is always the same as the initial value, which is fixed at A in these simulations. As the length of time increases, the four nucleotides converge on equal proportions of 0.25 each. 3.2.3 Analytical approach In all the examples above, I simulated replacement events by randomly generating them at the specified rate. To get the end state, I then just retained the last state. You could take this approach to assessing the probability of different outcomes in actual analyses, but it gets very computationally expensive. It would be better to have an equation to solve for the probabilities directly. That isn’t always possible for a model, but it is in this case. The process of change that our simple model describes is similar to compound interest. We have something in hand, apply a process to it, then take the output and apply that same process again. Over and over. In the case of compound interest, that something is money and the process is growth. In the case of our model, the something is a DNA site and the process is mutation. In both cases, we take is inputs a starting state, a rate of change, and an amount of time, and provide as an output get the expected end state. To get the expected end state as a function of time elapsed, given a rate of change, we can use exponential functions. For example, here is the exponential function for calculating a balance at time \\(B(t)\\) given the initial balance \\(B_0\\) and an interest rate \\(r\\): \\[\\begin{equation} B\\left(t\\right) = B_0 e^{r t} \\tag{3.2} \\end{equation}\\] For our sequence evolution model, we need two exponential functions (Swofford et al. 1996): \\[\\begin{equation} P\\left(t\\right) = \\frac{1}{4} + \\frac{3}{4} e^{-\\mu t} \\tag{3.3} \\end{equation}\\] \\[\\begin{equation} P\\left(t\\right) = \\frac{1}{4} - \\frac{1}{4} e^{-\\mu t} \\tag{3.4} \\end{equation}\\] Equation (3.3) shows the probability of the final state being the same as the beginning state. So if you start with an A, this would give you the probability of remaining an A after time \\(t\\) given a specific value of \\(\\mu\\). Equation (3.4) is the probability of each of the different end states. If you start as an A, this is the probability of changing to a G, for example. It is also the rate of C to T, G to A, etc… Consider what happens to these equations in the extremes we considered above when examining Figure 3.7. If \\(\\mu\\) or \\(t\\) are zero, we expect no change (Figure 3.8, left side). In that case we get \\(e^0\\), which is 1. Equation (3.3) becomes \\(1/4 + 3/4\\), which is 1. So there is a probability of 1 that, after no change, the end state is the same as the beginning state. Likewise, Equation (3.4) becomes \\(1/4 - 1/4\\), which is 0. So after no change the end states that differ from the beginning state each have probability 0. Now consider the case after infinite change (or just a large amount of change, as in the right side of Figure 3.8). If \\(\\mu\\) or \\(t\\) are infinity, then \\(e^{-\\mu t}\\) becomes \\(e^{-\\infty}\\), which is 0. In that case, Equation (3.3) becomes \\(1/4 + 0\\), which is simply \\(1/4\\). Likewise, Equation (3.4) becomes \\(1/4 - 0\\), which is also \\(1/4\\). So all the nucleotides (the one that you started with, and the three other states that substitution can lead to) all have the same equal frequency of \\(1/4\\). This reflects the fact that the frequency of drawing each of these from the bag was \\(1/4\\). Figure 3.8: The probability of observing a particular end state at time \\(t\\), given the start state A and \\(\\mu=0.05\\). The red line is the probability of observing the original start state (as described by Equation (3.3)), the blue line is the probability of observing each of the three other states (as described by Equation (3.4)). We can reorganize things a bit (Figure 3.8) to get a plot like that of Figure 3.7, but derived from Equations (3.4) and (3.4) instead of from actual simulations of changes along branches. Figure 3.9: Stacked bar plots indicating the frequency of each nucleotide after evolution for a specified amount of time. The rate of evolution is \\(\\mu=0.050\\). The starting state is set at A, so the probability of observing an A is described by Equation (3.3). The other three nucleotides, C, G, and T, are described by Equation (3.4). At time=0 (no evolution), the probability that the state is the same as at the start is 1.0. As the length of time increases, the four nucleotides converge on equal probability of 0.25 each. Let’s put this back into a biological context. Our simple model allows us to calculate the probability \\(P(t)\\) of a given nucleotide state at the end (child node) of an edge given: The nucleotide state at the beginning (parent node) of the edge Replacement rate \\(\\mu\\) Length of the edge \\(t\\) This is powerful stuff. We could do a variety of things with this model machinery, for example: Simulate evolution along an edge by sampling nucleotides for the child node from this probability distribution Ask the probability of a given starting state given an end state Evaluate how reasonable our \\(\\mu\\) model parameter value is. If, for example, we have a tree with very short edges that had different state at their parents and children, we might be skeptical of a low \\(\\mu\\) value. 3.3 Generalizing the simple model The model we built above only has one parameter that can vary, \\(\\mu\\), so we can describe the model parameters very simply. This is convenient, but leaves some of the things that are happening under the hood a bit opaque. Let’s rewrite this simple model in a way that makes it a bit clearer how we are using this parameter, and also reveals some other parameters that are there but that we ignored until now because they were clamped. First, we need to represent the model as a \\(4\\times4\\) rate matrix, which we will call \\(\\mathbf{Q}\\), as defined in Equation (3.5). Each row corresponds to one of the four possible nucleotides (A, C, G, T, in that order from top to bottom), and each column corresponds to one of the four possible nucleotides (A, C, G, T, in that order from left to right). Each of the elements in the matrix is the instantaneous rate of change from the nucleotide of the corresponding row, to the nucleotide of the corresponding column. \\[\\begin{equation} \\mathbf{Q} = \\left(\\begin{array}{cc} -3\\mu\\pi &amp; \\mu \\pi &amp; \\mu \\pi &amp; \\mu \\pi\\\\ \\mu\\pi &amp; -3\\mu \\pi &amp; \\mu \\pi &amp; \\mu \\pi\\\\ \\mu\\pi &amp; \\mu \\pi &amp; -3\\mu \\pi &amp; \\mu \\pi\\\\ \\mu\\pi &amp; \\mu \\pi &amp; \\mu \\pi &amp; -3\\mu \\pi\\\\ \\end{array}\\right) \\tag{3.5} \\end{equation}\\] Recall that \\(\\mu\\) is the rate of any replacement event happening. That replacement event could be an A, C, G, or T. Only three of these replacements lead to a substitution, since replacing with the original nucleotides does not lead to a change. To find the rate of specific replacements happening, as we need to do for the elements of this matrix, we need to apportion the total replacement rate \\(\\mu\\) to specific nucleotides. We can do that with a new term \\(\\pi\\), which is the name we will give to the equilibrium frequency of each state. This corresponds to the frequency of each nucleotide in the bag we randomly sampled from. In our simple model, \\(\\pi=0.25\\) for all nucleotides. Because \\(\\pi\\) was clamped and wasn’t free to vary, it was essentially invisible in the way we previously described the model. The off-diagonal elements of \\(\\mathbf{Q}\\) give the rates of substitutions, and are all \\(\\mu \\pi\\). But what’s up with the diagonal elements? Those correspond to replacements that do not lead to a substitution, for example an A being replaced be an A. We pick these diagonal elements to be whatever value leads the rows to sum to 0. Since there are three substitutions in each row, and each substitution has rate \\(\\mu \\pi\\), these diagonal elements are set to \\(-3 \\mu \\pi\\). The basic intuition of this is that we aren’t creating or destroying nucleotides, just replacing them. So the net change needs to be 0. There is a lot going in in \\(\\mathbf{Q}\\). To make sense of it all, it helps to factor it out into two parts (Swofford et al. 1996). The first is a \\(4\\times4\\) matrix \\(\\mathbf{R}\\), which has all the rates, and the second is a \\(4\\times4\\) matrix \\(\\Pi\\) that has the equilibrium frequencies on its diagonal and 0 everywhere else (Equation (3.6)). \\[\\begin{equation} \\mathbf{Q} = \\mathbf{R}\\mathbf{\\Pi} = \\left(\\begin{array}{cc} -3\\mu &amp; \\mu &amp; \\mu &amp; \\mu\\\\ \\mu &amp; -3\\mu &amp; \\mu &amp; \\mu\\\\ \\mu &amp; \\mu &amp; -3\\mu &amp; \\mu\\\\ \\mu &amp; \\mu &amp; \\mu &amp; -3\\mu\\\\ \\end{array}\\right) \\left(\\begin{array}{cc} \\pi &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\pi &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp;\\pi &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp;\\pi\\\\ \\end{array}\\right) \\tag{3.6} \\end{equation}\\] (This factoring is possible because of the way matrix multiplication works. For a refresher on matrix multiplication, this video explains how to do it operationally, and this series of videos explains what it is actually doing.) \\(\\mathbf{Q}\\) is the instantaneous rate matrix – it specifies the particular amount of change we expect over a short period of evolutionary time. But as we discussed before, we often want to know the probability of ending with a particular state if you start with a particular state and let it evolve along an edge of a given length. Before, when we were keeping things as simple as possible, we used the exponential Equations (3.3) and (3.4) for this. They took as input the overall replacement rate \\(\\mu\\) and the length of the edge \\(t\\). Now we want a similar equation, but we want to provide the rate matrix \\(Q\\) rather than the single parameter \\(\\mu\\). Again we can just use an exponential function, and it actually has a much simpler form. \\[\\begin{equation} \\mathbf{P}\\left(t\\right) = e^{\\mathbf{Q} t} \\tag{3.7} \\end{equation}\\] Raising \\(e\\) to the power of a matrix like this is known as matrix exponentiation, and it returns a matrix with the same dimensions as the matrix in the exponent. This new matrix \\(\\mathbf{P}(t)\\) is therefore also a \\(4\\times4\\) matrix. As for \\(\\mathbf{Q}\\) and \\(\\mathbf{\\Pi}\\), and \\(\\mathbf{R}\\), each row corresponds to one of the four possible nucleotides (A, C, G, T), and each column corresponds to one of the four possible nucleotides (A, C, G, T). Each of the elements in the matrix is the probability of going from the nucleotide of the corresponding row to the nucleotide of the corresponding column over an edge of length \\(t\\). The diagonal elements are each Equation (3.3), and the off diagonal elements are each Equation (3.4). Wow! This was a lot of work to write a really simple model in a much more complicated way. Now we can start to reap the rewards of describing this simple model in this form. 3.4 Expanding the models The mathematical, statistical, and computational machinery above describes the evolution of one DNA site along one edge in a phylogeny (Figure 3.3) according to a simple model. In fact, this is the simplest possible model of DNA evolution, named JC69 after the folks who described it in 1969 (Jukes and Cantor 1969). It is only one free parameter – the rate of evolution \\(\\mu\\). It is highly idealized – there are many important facts about DNA and DNA evolution that it deliberately omits. The simplicity of JC69 makes it a useful starting place to understand how models of DNA evolution work, but it is too simple to be very useful in practice. There are many other biological aspects of sequence evolution we might want to consider, including that: The nucleotides C, G, T, and A are often not found at an equal frequency of 0.25 each. Since the nucleotides form base pairs in organisms with double stranded genomes, C and G are found at the same frequency and T and A at the same frequency. Furthermore, the frequency of the four nucleotides must add to 100%. Therefore, the frequency of all four nucleotides can be summarized with a single number, usually given as the GC content – the percent of sites that are G or C. For example, the human genome has a GC content of 41%, which indicates nucleotide frequencies of 0.205 G, 0.205 C, 0.295 T and 0.295 A. This is quite different than the equal frequencies of 0.25 for all nucleotides expected by the JC69 model. The rates of mutation between different nucleotides is not the same. This is in part because some nucleotides are shaped more like others, and are more likely to be substituted for each other by mistake. In particular, A and G tend to be substituted for each other because they have two rings, and C and T tend to be substituted for each other because they have one ring. These changes between A/G and C/T are referred to as transitions. All other substitutions are called transversions, and are each less likely. To accommodate each of these deviations from JC69, we need to add parameters to the model to explain the added complexity. There are all kinds of parameters we could add one by one, and in fact that is how the field proceeded in the decades after JC69 was described. Rather than build the models up in that way, though, it is actually easier to describe a general model that these other models, including JC69, are special cases of. \\[\\begin{equation} \\mathbf{Q} = \\mathbf{R}\\mathbf{\\Pi} = \\left(\\begin{array}{cc} - &amp; \\mu a &amp; \\mu b &amp; \\mu c\\\\ \\mu a &amp; - &amp; \\mu d &amp; \\mu e \\\\ \\mu b &amp; \\mu d &amp; - &amp; \\mu f \\\\ \\mu c &amp; \\mu e &amp; \\mu f &amp; -\\\\ \\end{array}\\right) \\left(\\begin{array}{cc} \\pi_A &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\pi_C &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp;\\pi_G &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\pi_T \\\\ \\end{array}\\right) \\tag{3.8} \\end{equation}\\] (To keep things compact, I have followed the convention of placing \\(-\\) in the diagonal elements, which is short for “whatever it takes to make the rows of \\(\\mathbf{Q}\\) sum to 0”.) This model (Equation (3.8)) is called the General Time Reversible (GTR) model of DNA sequence evolution. It is General because it has parameters that allow many things to vary independently. The \\(\\pi_A ... \\pi_T\\) parameters allow the equilibrium frequencies to differ for each nucleotide. The \\(a ... f\\) parameters adjust \\(\\mu\\) so that rates can differ. For example, the instantaneous rate of change from A to C can be different from that of A to G by setting \\(a\\) and \\(b\\) to different values. It is Time Reversible because we don’t have different rate parameters for every single off-diagonal element, but instead mirror them. This means, for example, that the rate of change from A to C and from C to A are both the same, \\(\\mu a\\). There are a few motivations for this. It keeps the total number of parameters down. It reflects what is observed biologically. And it means that we don’t need to know the direction of time along an edge to calculate \\(\\mathbf{P}(t)\\). This last point is very important since we often don’t know where the root of a tree is when we want to calculate these probabilities. It also turns out to be convenient and efficient for phylogenetic inference software tools to reroot phylogenies without changing these probabilities as they make calculations on phylogenies. If we let all the parameters in the GTR model (Equation (3.8)) be free, it is quite complex. We would have to estimate them all from data. The alternative is clamp some of them. In fact, by comparison of Equations (3.6)) and (3.8), we can see that JC69 is a clamped version of GTR where \\(\\pi_A=\\pi_C=\\pi_G=\\pi_T=0.25\\) and \\(a=b=c=d=e=f=1\\). Only \\(\\mu\\) is left free in JC69. There are a variety of other commonly used models that clamp these parameters in different ways, some leaving more freedom than others. Some that are widely used and have very specific biological motivation have their own names, like JC69 (the motivation for this model is that it is so simple). Examples of other named models include: HKY85 differs from GTR in setting some rate modifiers equal to each other so that there are two rates, \\(b=e\\) for transitions (A to G, and C to T) and \\(a=c=d=f\\) for transversions (all other changes). It still lets all the \\(\\pi\\) parameters vary independently. F81 differs from HKY85 in that it sets all the rate modifiers to 1, so that \\(a=b=c=d=e=f=1\\). It is almost as simple as JC69, except that the \\(\\pi\\) parameters vary independently. We now have a more complex model of DNA evolution that we can simplify by setting the parameters to equal each other and/or clamping them to specific values. It can accommodate much of variation observed in actual DNA sequence data. We could use it to simulate data just as we did in Figure 3.7, but taking into consideration things like unequal nucleotide frequencies and differences in rates of change between nucleotides. This is getting us much closer to something that provides real biological insight. 3.5 Plugging some numbers into the expanded model Now that we have a framework for specifying a model with unequal equilibrium frequencies and different rates of change between different nucleotide pairs, let’s build a specific case of a model and use it to simulate some data. That means we need to pick some actual model parameters, plug them into \\(\\mathbf{R}\\) and \\(\\mathbf{\\Pi}\\) to get \\(\\mathbf{Q}\\), and then exponentiate that to get \\(\\mathbf{P}(t)\\). We can then use that to simulate changes in a single nucleotide along an edge. This will be a mathematically grounded version of the schematic in Figure 3.3B. We are using a mammal tree, so let’s pick some parameter values that roughly approximate what we see in mammals. Rather than set all the parameters independently, let’s set up an HKY85 model, which accommodates non-uniform base frequencies and different transition/ tansversion ratios. First, we can clamp \\(\\mu=1\\). This basically just means the branch lengths will be in units of expected evolutionary change. Transitions (captured by parameters \\(b\\) and \\(e\\)) are on the order of 4 times more frequent than transversions (captured by parameters \\(a\\), \\(c\\), \\(d\\), and \\(f\\)) in mammals (Rosenberg, Subramanian, and Kumar 2003). So we will clamp \\(b=e=2\\) and \\(a=c=d=f=0.5\\). I picked these particular values (rather than others, such as 4 and 1) because they keep the mean of the off-diagonal entries in \\(\\mathbf{R}\\) to 1. Now we have the following values for \\(\\mathbf{R}\\): \\[ \\mathbf{R} = \\left(\\begin{array}{cc} - &amp; 0.5 &amp; 2 &amp; 0.5 \\\\ 0.5 &amp; - &amp; 0.5 &amp; 2 \\\\ 2 &amp; 0.5 &amp; - &amp; 0.5 \\\\ 0.5 &amp; 2 &amp; 0.5 &amp; - \\\\ \\end{array}\\right) \\] We won’t specify the diagonal elements of \\(\\mathbf{R}\\) quite yet. Now we need \\(\\mathbf{\\Pi}\\). We noted earlier that humans have a GC content of 41%, so we’ll use that. This gave the following entries for \\(\\mathbf{\\Pi}\\): \\[ \\mathbf{\\Pi} = \\left(\\begin{array}{cc} 0.295 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0.205 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0.205 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0.295 \\\\ \\end{array}\\right) \\] Now we can calculate \\(\\mathbf{Q}\\) by multiplying \\(\\mathbf{R}\\) and \\(\\mathbf{\\Pi}\\) and adjusting the diagonal so that the rows each sum to 0: \\[ \\mathbf{Q} = \\mathbf{R\\Pi} = \\left(\\begin{array}{cc} -0.6600 &amp; 0.1025 &amp; 0.4100 &amp; 0.1475 \\\\ 0.1475 &amp; -0.8400 &amp; 0.1025 &amp; 0.5900 \\\\ 0.5900 &amp; 0.1025 &amp; -0.8400 &amp; 0.1475 \\\\ 0.1475 &amp; 0.4100 &amp; 0.1025 &amp; -0.6600 \\\\ \\end{array}\\right) \\] This is our instantaneous rate matrix. From here on out I will switch from mathematical notation to computational representations, since we are doing more calculations. Here is what the contents of \\(\\mathbf{Q}\\) look like when outputted from R: ## A C G T ## A -0.6600 0.1025 0.4100 0.1475 ## C 0.1475 -0.8400 0.1025 0.5900 ## G 0.5900 0.1025 -0.8400 0.1475 ## T 0.1475 0.4100 0.1025 -0.6600 Now we need to exponentiate \\(\\mathbf{Q}\\) it to get \\(\\mathbf{P}(t)\\), according to Equation (3.7). If we do that numerically, we need to specify \\(t\\) before we do the exponentiation. So, for example, \\(\\mathbf{P}(1)\\) is: ## A C G T ## A 0.5913935 0.08066121 0.21187182 0.1160735 ## C 0.1160735 0.49837662 0.08066121 0.3048887 ## G 0.3048887 0.08066121 0.49837662 0.1160735 ## T 0.1160735 0.21187182 0.08066121 0.5913935 The sum of each row of \\(\\mathbf{P}(t)\\) is 1 for any value of \\(t\\), since our model doesn’t create or destroy nucleotides no matter how long the edge. No matter which of the four nucleotides you start with, you have to end with one of the four nucleotides. This better demonstrates why we had to select diagonal values of the rate matrix \\(\\mathbf{Q}\\) so that each row in that matrix is 0 – if we hadn’t, then the row sums of \\(\\mathbf{P}(t)\\) would not be 1. Now that we can derive \\(\\mathbf{P}(t)\\), let’s explore some of its properties. Let’s first think about what happens when \\(t=0\\). In this case, there is no time for evolution to occur and the resulting nucleotide should be the same as the starting nucleotide. Indeed, we see this is the case: ## A C G T ## A 1 0 0 0 ## C 0 1 0 0 ## G 0 0 1 0 ## T 0 0 0 1 The probability of going from A to A is 1 while the probability of going from any other nucleotide is 0. The same goes for all of the other nucleotides, giving ones on the diagonal and zeros everywhere else. What if the edge is very long, say \\(t=100\\)? ## A C G T ## A 0.295 0.205 0.205 0.295 ## C 0.295 0.205 0.205 0.295 ## G 0.295 0.205 0.205 0.295 ## T 0.295 0.205 0.205 0.295 In this case, each row has the exact same values. If you look closely, they should be familiar – they are the equilibrium frequencies from \\(\\mathbf{\\Pi}\\). This matches what happened in Figures 3.7 and 3.8. As edge length increases, the expected frequencies of each nucleotide deviate further and further from the original state and approach the equilibrium frequencies specified by \\(\\mathbf{\\Pi}\\). 3.6 Simulation along a single edge We can now calculate the probability of a specific end state given a start state. Now let’s use this machinery to simulate evolution along a single edge at a time, as in Figure 3.3B. We first need to set the state at the parent node. There are a couple approaches we could use to set the parent state. We could clamp it to a specific initial state, just as we did in our JC69 simulations when we set the starting state to A (Figure 3.4). Alternatively, we could pick the starting state at random. How do we select a starting state at random? We could draw the starting state from a bag with equal frequencies of each nucleotide (as we did at the beginning of this chapter), but our model allows us to make a more informed selection than that. We implemented \\(\\mathbf{\\Pi}\\) because we wanted to describe cases where the nucleotides do not occur at uniform frequencies, so let’s draw from that distribution instead. For the toy mammal model we made above, that is 0.205 G, 0.205 C, 0.295 T and 0.295 A. We just sample a single nucleotide from this probability distribution. Table 3.1: Each row is simulated evolution along a single edge. Parent Length Child A 0.0387691 A A 0.3444866 A C 0.6561006 A C 0.6723020 C A 0.5311025 A A 0.7477842 G T 1.7042348 T A 0.6896113 G G 0.7347406 G G 1.3263353 G In Table 3.1 I selected the Parent nucleotide by sampling from \\(\\mathbf{\\Pi}\\) as described above. I then created a random edge length \\(t\\) by sampling from a uniform distribution that ranges from 0 to 2, just to get a variety of edge lengths. I then simulated the Child state by sampling from \\(\\mathbf{P}(t)\\) given \\(t\\) and the Parent state. 3.7 Scaling from a single edge to a whole tree So far we have considered the evolution of one DNA site along one edge at a time (Figure 3.3B, Table 3.1). We will now expand to a whole tree, keeping our focus for now on simulation. Our goal is to use the model to simulate the evolution of a single site along all edges, generating a specific nucleotide state at each node. We will use the same toy mammal model as above. We will consider a simplified tree (Figure 3.10) rather than the full mammal tree, just to keep things compact. Figure 3.10: Simulation of states for a single DNA site on a simple tree according to our toy mammal model. Node numbers are in red. Character states are in boxes at nodes. Branch lengths for this phylogram are in units of expected change. This isn’t a big step from what we have already – once we have all the machinery to simulate along a single edge, we can just iterate that to simulate evolution along a whole tree. Let’s start with the root of the tree (Figure 3.10, node 5). As in our simulations along single edges, we will pick the state from the equilibrium frequencies \\(\\mathbf{\\Pi}\\). That gives us the A at the root in Figure 3.10. The root node is the parent of two edges that descend from it. These two edges connect to node 6 (the most recent common ancestor of the clade (Species_A, Species_B)) and node 7 (the most recent common ancestor of the clade (Species_C, Species_D)). We simulate the states for these child nodes according to the state at the root (node 5), length \\(t\\) of each edge, and \\(\\mathbf{P}(t)\\). In each case, this is just as when we simulated evolution along a single edge at a time, it is just that the edges share a parent node so the also share a parent state. There are four more edges in this tree, each connected to a terminal node. One edge has parent node 6 and child node 1 (which is the Species_A terminal node). Now that we are not at the root things are a little different. Rather than draw the state for the parent node from \\(\\mathbf{\\Pi}\\), we just use the state that was simulated along the edge connecting node 5 to node 6. This state is A. Now we simulate evolution along the edge connecting node 6 to node 1, given the state at node 6, length \\(t\\) of the edge, and \\(\\mathbf{P}(t)\\). We then do the same for each of the other edges. Data can be simulated on a tree of arbitrary size in this way. Just sample from \\(\\mathbf{P}(t)\\) for the root state. Then traverse the tree from the root to each of the tips, simulating the state at each of the other internal nodes and finally the terminal nodes according to the states of their parents, edge length \\(t\\), and \\(\\mathbf{P}(t)\\). 3.8 Scaling from a single site to multiple sites So far we have considered evolution at a single DNA site across a whole phylogeny. Genomes have from thousands to billions of sites, though. Here we expand our simulations from a single nucleotide at a time to arbitrarily long DNA sequences. How? With one simplifying assumption – that the evolution of each site is independent of the evolution at other sites. We just simulate one site at a time, and then stick all the results together into a sequence. 3.9 Concluding thoughts Here we have built up the conceptual, mathematical, statistical, and computational machinery to simulating DNA evolution on a tree. Sequence simulation is useful for a variety of things, including generating datasets under known conditions to test tools. A major value, though, is to to think in a full explicit way about how you are modeling evolution. This probabilistic model framework is the exact same one we will use as we move to our next task, inferring phylogenies from sequence data. 3.10 Additional resources As a grad student, I learned much of what I present here from [swofford1996molecular]. This is an incredibly lucid chapter, and the foundation for my own understanding of how to think about the likelihood of molecular sequence data on a phylogeny. My own thinking about presenting this material was heavily influenced by Paul Lewis’s wonderful lectures at the annual Workshop on Molecular Evolution at Woods Hole. Some of his lectures are now available online as part of the excellent Phylo Seminar, starting with https://www.youtube.com/watch?v=1r4z0YJq580&amp;t=2111s A great introduction to continuous time models by John Huelsenbeck https://revbayes.github.io/tutorials/dice/ References "],
["inferring-phylogenies-from-data.html", "Chapter 4 Inferring phylogenies from data 4.1 Probability of a single history 4.2 Probability of multiple histories 4.3 Log likelihood 4.4 Likelihood for multiple sites 4.5 Maximum likelihood 4.6 Optimality criteria", " Chapter 4 Inferring phylogenies from data In the previous chapter we built modeling machinery that allowed us to specify a rate matrix \\(\\mathbf{Q}\\) (Equation (3.8)), and from that derive the matrix \\(\\mathbf{P}(t)\\) (Equation (3.7)) that gives the probability of a particular end state given the starting state and the edge length \\(t\\). We used \\(\\mathbf{P}(t)\\) in a generative context, to simulate the evolution of a DNA sequence along the edges of a phylogeny. We will now turn to using the same statistical framework for what may initially seem to be a very different task – phylogenetic inference, where we infer the topology and edge lengths of a phylogeny from character data (DNA sequences, in this case). But these tasks are similar conceptually. The basic intuition is that you can infer a phylogeny by looking for the topology and edge lengths that are most probable to generate the observed data (Felsenstein 1981). This relationship between simulation and inference is widely used in a variety of fields. The probability of the observed data given a hypothesis is referred to as the Likelihood. Searching for the most likely hypothesis is referred to as Maximum Likelihood (ML). 4.1 Probability of a single history We will consider the toy phylogeny, along with its tip states, shown in Figure 4.1. Figure 4.1: The toy phylogeny we will use to examine inference. Node numbers are in red. Edge lengths are in orange. Tip node states are within boxes. We will start be calculating the probability of a single history of evolution for a single site on a single phylogeny with specified topology and edge lengths. This history is the full set of states at all nodes. These are added to the toy phylogeny in Figure 4.2. I want to emphasize that this isn’t a history we have any particular reason to believe, it is just one possible history of states randomly chosen from all the possible histories. Figure 4.2: The same toy tree as above, but with arbitrary internal node states (in boxes). Our goal now is to calculate the probability of each observed change. Recall that the matrix that contains these probabilities, given a starting state (rows), ending state (columns), and edge length \\(t\\), is given by: \\[\\begin{equation} \\mathbf{P}\\left(t\\right) = e^{\\mathbf{Q} t} \\tag{4.1} \\end{equation}\\] Where \\(\\mathbf{Q}\\) is the rate matrix. Let’s plug some numbers in using the model we specified in the previous chapter. We don’t have any specific reason to use this model on this tree, we are just sticking with it since we already built it. Here is the relative rate matrix \\(\\mathbf{R}\\): ## A C G T ## A 0.0 0.5 2.0 0.5 ## C 0.5 0.0 0.5 2.0 ## G 2.0 0.5 0.0 0.5 ## T 0.5 2.0 0.5 0.0 The equilibrium frequencies \\(\\mathbf{\\Pi}\\): ## A C G T ## A 0.295 0.000 0.000 0.000 ## C 0.000 0.205 0.000 0.000 ## G 0.000 0.000 0.205 0.000 ## T 0.000 0.000 0.000 0.295 And their product \\(\\mathbf{Q}\\), with the diagonal adjusted so that rows sum to 0: ## A C G T ## A -0.6600 0.1025 0.4100 0.1475 ## C 0.1475 -0.8400 0.1025 0.5900 ## G 0.5900 0.1025 -0.8400 0.1475 ## T 0.1475 0.4100 0.1025 -0.6600 For each edge, we can now use \\(\\mathbf{P}(t)\\) to calculate the probability of a change from the start state at the parent node to the end state at the child node, given the edge length \\(t\\). The results are shown in Figure 4.3. Figure 4.3: The same toy tree as above, but with probabilities of the specific change along each edge (in blue). Now that we have the probabilities of each of these changes, we can calculate the joint probability of all these changes. When we want to calculate the joint probability of multiple independent events, we take the product of the probability of each specific event. For example, the probability of rolling a 4 on a fair die is \\(1/6\\). The probability of rolling two 4s on two fair dice is \\(1/6\\times1/6=1/36\\). So we can take the product of all the blue probabilities to calculate the joint probability of all of these events happening. We can think of these as the probabilities of specific changes along each edge as the probabilities of the state at each child node. node probability 1 0.7442034 2 0.7442034 3 0.3048887 4 0.2260230 5 NA 6 0.0195083 7 0.0652538 Note, though, that the probability for node 5 is missing (it has a value of NA, which means it is Not Available). By reference to Figure 4.3 we can see that this is the root node. This makes sense since the root is not the child of any edge, and we calculated the probabilities based on changes along edges. We will therefore assess the probability of the root node state according to \\(\\mathbf{\\Pi}\\), the equilibrium frequencies. This is the same approach we took when simulating data on a tree. When we fill that in our full set of probabilities is: node probability 1 0.7442034 2 0.7442034 3 0.3048887 4 0.2260230 5 0.2950000 6 0.0195083 7 0.0652538 The joint probability of all these states can now be calculated as the product of each state. This comes out to \\(1.4332602\\times 10^{-5}\\). There are multiple ways to think about this probability. One is from a frequentist perspective. If we were to simulate character states on this tree, we would expect this full set of character states to occur at a frequency of 14.3 times out of a million simulations. Here we have used much of the same machinery as we did in the previous chapter, but toward a slightly different end. Rather than use the probability distributions to generate nucleotides in a simulation, we instead calculated the probability of a particular set of nucleotides. These may have seemed like very different tasks at first blush, but as you can now see their mathematical implementation shares many features. 4.2 Probability of multiple histories Above we considered the joint probability of a specific set of nucleotide states at all nodes, including both tip nodes and internal nodes. Usually, though, we don’t know the internal node states. We don’t even know what internal nodes exist, which is why we are trying to infer the phylogeny! Instead we have observed states that we got by sequencing organisms at the tips. We want to clamp these tip states and assess their probability on a particular tree (with edge lengths) under the model. This probability is independent of a specific history of internal node states. If we aren’t clamping the internal node states as well, how can we calculate the probability of just the tip node states? The key is to consider all possible internal states. Each configuration of internal node states represents one possible history that gave rise to the observed tip states. We can sum the probabilities of each of these different ways to get the tip states to find the probability of the tip states over all possible histories. We are summing the probabilities because these are mutually exclusive histories that could give rise to the observed data. For example, if we want to find the probability of getting a total of seven when rolling two dice, we need to add up the probability of each way to get seven (1+6 or 2+5 or 3+4 or … 6+1). This is different from when we multiplied probabilities to find the joint probabilities of multiple events occurring together (e.g., the probability of rolling a 4 and another 4). This is a small tree, with only 3 internal nodes that can each have 4 states. This gives \\(4^3=64\\) possible histories. That is small enough to list them out below. I also include the probability of each specific history, calculated exactly as I did above (the example above corresponds to row 60 here). n1 n2 n3 n4 n5 n6 n7 probability T T A C A A A 0.0000451 T T A C C A A 0.0000048 T T A C G A A 0.0000036 T T A C T A A 0.0000035 T T A C A C A 0.0000000 T T A C C C A 0.0000025 T T A C G C A 0.0000000 T T A C T C A 0.0000002 T T A C A G A 0.0000005 T T A C C G A 0.0000005 T T A C G G A 0.0000044 T T A C T G A 0.0000004 T T A C A T A 0.0000000 T T A C C T A 0.0000003 T T A C G T A 0.0000000 T T A C T T A 0.0000019 T T A C A A C 0.0000282 T T A C C A C 0.0000030 T T A C G A C 0.0000023 T T A C T A C 0.0000022 T T A C A C C 0.0000018 T T A C C C C 0.0002699 T T A C G C C 0.0000013 T T A C T C C 0.0000164 T T A C A G C 0.0000012 T T A C C G C 0.0000011 T T A C G G C 0.0000097 T T A C T G C 0.0000008 T T A C A T C 0.0000006 T T A C C T C 0.0000069 T T A C G T C 0.0000004 T T A C T T C 0.0000432 T T A C A A G 0.0000088 T T A C C A G 0.0000009 T T A C G A G 0.0000007 T T A C T A G 0.0000007 T T A C A C G 0.0000000 T T A C C C G 0.0000018 T T A C G C G 0.0000000 T T A C T C G 0.0000001 T T A C A G G 0.0000017 T T A C C G G 0.0000016 T T A C G G G 0.0000142 T T A C T G G 0.0000011 T T A C A T G 0.0000000 T T A C C T G 0.0000002 T T A C G T G 0.0000000 T T A C T T G 0.0000013 T T A C A A T 0.0005139 T T A C C A T 0.0000552 T T A C G A T 0.0000415 T T A C T A T 0.0000400 T T A C A C T 0.0000071 T T A C C C T 0.0010512 T T A C G C T 0.0000050 T T A C T C T 0.0000638 T T A C A G T 0.0000214 T T A C C G T 0.0000198 T T A C G G T 0.0001776 T T A C T G T 0.0000143 T T A C A T T 0.0000366 T T A C C T T 0.0004512 T T A C G T T 0.0000255 T T A C T T T 0.0028111 Note that I listed the states for all the nodes, including nodes 1-4, which are clamped. It is the last three internal nodes (n5-n7) that have variable states. The probabilities for each specific history range quite widely, from \\(8.2902428\\times 10^{-9}\\) to \\(0.0028111\\). The sum of the probabilities for each of these different histories for n5-n7 that give rise to the observed clamped states for tip nodes n1-n4 is \\(0.0058252\\). This probability of the data given a particular hypothesis (the topology, edge lengths, model, and model parameters) is the likelihood. 4.3 Log likelihood The likelihood of these data on this phylogeny, \\(0.0058252\\), is not a big number. And this is a very small tree. As trees get larger there are many more probabilities we need to multiply, so the products get even smaller. The joint probabilities, in fact, get so small that computers have trouble storing them efficiently. Rather than store and manipulate the small probabilities directly, most tools take the natural logs of the probabilities, \\(ln(p)\\). The log likelihood for this phylogeny is \\(-5.1455597\\). Taking the log transforms probabilities to a numerical representation that is easier to work with. It also has the added value of making calculations of joint probability simpler. Given the relationship between the log of products of variables and the sum of logs of each value: \\[\\begin{equation} ln(a)+ln(b) = ln(ab) \\tag{4.2} \\end{equation}\\] We can calculate joint log probabilities as sums of log probabilities for each event, rather than as the log of products of the probabilities. Addition is much faster than multiplication for computers (since multiplication is a series of addition operations), so this speeds things up. For these reasons you will almost always see log likelihoods, rather than just likelihoods, published in the literature. Note that because likelihoods are probabilities and therefore range from 0–1, the log likelihoods will range from \\(-\\infty\\) (for probabilities very close to 0) to \\(0\\) (for probabilities close to 1). Since likelihoods tend to be small, they end up as log likelihoods that are negative numbers with large absolute values. 4.4 Likelihood for multiple sites The machinery above gives us everything we need to calculate the log likelihood of a specific pattern of nucleotides across tips for a single site in a DNA sequence. We new need to expand this model from a single site to multiple sites within a gene or even across whole genomes. This comes down to more of the same. We do everything we did above for each site, and then sum the log likelihoods across sites. This gives us the joint probability of observing the data seen across tips for each site in the DNA sequence. This joint probability for all sites will be much smaller than the probability for each individual site. 4.5 Maximum likelihood At this point we can calculate the log likelihood for specified phylogenies, models, and DNA sequences. But we set out to do phylogenetic inference, where we estimate phylogenies from sequences at tips. How do we get there from here? Once we can calculate the likelihood of a given phylogeny, we can calculate the likelihood of any phylogeny. We can then search for the phylogeny with the maximum likelihood (and, of course, maximum log likelihood). The small toy phylogeny considered here (Figure 4.1) has four tip nodes. Be reference to Equation (2.1), we can see that there are 15 possible topologies. For each, we can optimize the edge lengths to find the maximum likelihood for the topology. This is an iterative process, where each edge length is progressively refined until no change increases the likelihood. This excellent interactive visualization allows you to manually optimize edge lengths on a small phylogeny. Then we pick the topology with the maximum likelihood. This requires a very large number of calculations, but is doable for every possible topology. Things change very quickly, though, as trees grow in size. Beyond about 15 tips there are so many possible topologies that it is impossible to calculate the likelihood for every topology using existing computer hardware and software. That means it is necessary to use heuristics - to modify the tree you have until you can do no better. This is like hill climbing. You calculate the likelihood of a tree and then modify it. If the likelihood is higher, you keep it, if it is worse, you discard it. This might sound simple, but it isn’t. One challenge is that you can get trapped on a local maximum and mistake it for the best phylogeny, when in fact there are other phylogenies with very different topologies that are much better but not locally accessible. There is extraordinary craft that goes into building tools that are able to efficiently climb these likelihood surfaces without getting trapped in local maxima. Optimization of calculations becomes very important. For example, it isn’t necessary to recalculate all values on each new topology, since some of the calculations from previous topologies remain relevant (Felsenstein 1981). 4.6 Optimality criteria Here we used likelihood as an optimality criterion to search over treespace, the set of all possible phylogenies, to find the phylogeny that maximizes the criterion. There are other optimality criteria that are used in phylogenetic inference. These include parsimony. In parsimony, the minimum number of changes along edges needed to explain the data at the tips is used as the criterion to evaluate each topology. Optimization proceeds by attempting to identify the topology that requires the fewest changes. This requires far less computational power than likelihood, so searches are faster. Under some conditions parsimony and likelihood will recover similar topologies, but often they do not. This is because they are doing different things that under many conditions lead to different results (Steel and Penny 2000). For example, we do not always expect the simplest possible explanation for a given pattern to be the best explanation. If a character has a high rate of evolutionary change, then we expect many changes on a tree rather than the fewest possible. This is accommodated in a likelihood framework. References "],
["inference-in-practice.html", "Chapter 5 Inference in practice 5.1 Homologous genome regions 5.2 Homologous sites 5.3 Model selection 5.4 Running the inference 5.5 Viewing results 5.6 Interpretting results", " Chapter 5 Inference in practice In the last chapter we examined the mathematical and statistical underpinning of phylogenetic inference with maximum likelihood. In this chapter we examine the practice of phylogenetic inference – what are the actual steps you need to take to infer topology and edge lengths? We are sticking with DNA sequence data for now, but we will extend these approaches to other types of data later. 5.1 Homologous genome regions 5.2 Homologous sites Sequence orientation multiple sequence alignment 5.3 Model selection 5.4 Running the inference 5.5 Viewing results 5.6 Interpretting results "],
["evaluation.html", "Chapter 6 Evaluation 6.1 Model evaluation 6.2 Topology evaluation 6.3 Sensitiviy 6.4 Confidence 6.5 Epistemology", " Chapter 6 Evaluation 6.1 Model evaluation Why not add as many parameters as you can imagine? Likelihood ratio test AIC BIC 6.2 Topology evaluation 6.3 Sensitiviy changing methods and parameters adding noise 6.4 Confidence Propogation, point estimates 6.5 Epistemology gene trees, species trees "],
["future.html", "Chapter 7 Future", " Chapter 7 Future Integrated models of genome evolution "],
["shape.html", "Chapter 8 Shape", " Chapter 8 Shape Dating Diversification Extinction, birth, death Null models "],
["character-evolution.html", "Chapter 9 Character evolution", " Chapter 9 Character evolution Comparative biology Reconstructing a single trait on trees Trait correlation Models of character change, including rate "],
["applications.html", "Chapter 10 Applications 10.1 Functional genomic data 10.2 Gene trees", " Chapter 10 Applications 10.1 Functional genomic data 10.2 Gene trees "],
["references.html", "References", " References "]
]
